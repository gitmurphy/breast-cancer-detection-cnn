{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6718c38c",
   "metadata": {},
   "source": [
    "### Convert the images from DICOM to PNG format \n",
    "\n",
    "The CNN models in this study do not support DICOM formatting, making conversion to PNG the first necessary step in data pre-processing. The script used will iterate through the images and systematically convert them to .png files in a new folder. The script will also ensure that the original folder structure is preserved, to retain access as intended to the associated categorical data found in accompanying csv files. The images will be individually normalized as part of this process to stretch the range of pixel intensities, improving contrast and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "\n",
    "# Input folder - DICOM files\n",
    "input_folder = r'E:\\vindr-mammo-1.0.0\\images'\n",
    "# Output folder - PNG files\n",
    "output_folder = r'E:\\vindr-mammo-1.0.0\\png_images'\n",
    "\n",
    "# Iterate through sub-folders and files\n",
    "for root, folders, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dicom\"):\n",
    "            dicom_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(root, input_folder)\n",
    "            output_subfolder = os.path.join(output_folder, relative_path)  # Maintain original folder structure\n",
    "            os.makedirs(output_subfolder, exist_ok=True)  # Create output subfolder\n",
    "            output_path = os.path.join(output_subfolder, file.replace('.dicom', '.png'))\n",
    "            dicom_file = pydicom.dcmread(dicom_path)\n",
    "            img = dicom_file.pixel_array\n",
    "\n",
    "            if img.max() > 255:\n",
    "                img = (img - img.min()) / (img.max() - img.min()) * 255    # Normalize images (Stretch range of pixel intensities)\n",
    "                img = img.astype('uint8')\n",
    "\n",
    "            cv2.imwrite(output_path, img)  # Save as PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0a460",
   "metadata": {},
   "source": [
    "### Resize the images\n",
    "\n",
    "After converting the images, they should be resized for use with CNNs – most models require consistent input dimensions. Resizing the images makes sure all of them are consistent in size. Standardizing the size also reduces the computational load and ensures the models can process the data efficiently. The images are resized to 256x256, which works well with most CNN models. Using cv2.INTER_AREA preserves image quality when downscaling through the use of pixel resampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "images_folder = r'E:\\vindr-mammo-1.0.0\\png_images'\n",
    "\n",
    "# Load images into a list\n",
    "all_images = []\n",
    "for root, _, files in os.walk(images_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):  # Only process PNG images\n",
    "            all_images.append(os.path.join(root, file))\n",
    "\n",
    "# Loop through images and resize - including progress bar\n",
    "for img_path in all_images:\n",
    "    img = cv2.imread(img_path)\n",
    "    resized_img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA) # INTER_AREA better for downscaling\n",
    "    cv2.imwrite(img_path, resized_img)  # Overwrite original images (not necessary to retain them)\n",
    "\n",
    "print('Resizing Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b70ed",
   "metadata": {},
   "source": [
    "### Apply CLAHE contrast enhancement\n",
    "\n",
    "CLAHE (Contrast Limited Adaptive Histogram Equalization) considers the global contrast of\n",
    "the image. With CLAHE the image is split into multiple sections or ‘tiles’ which are\n",
    "individually equalized to avoid darker tiles influencing lighter ones. It is particularly common\n",
    "with medical images to find large areas of low contrast. Using OpenCV’s cv2 library this\n",
    "equalization method can be easily applied to the images in this dataset. As with each step in\n",
    "this process, special care is also taken in order to preserve the original folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ac6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = r'E:\\vindr-mammo-1.0.0\\png_images'\n",
    "clahe_images_folder = r'E:\\vindr-mammo-1.0.0\\clahe_images'\n",
    "\n",
    "os.makedirs(clahe_images_folder, exist_ok=True)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0) # clip limit recommended by OpenCV. Tile size is 8x8 by default\n",
    "\n",
    "# Loop through study ids to preserve folder structure\n",
    "for study_id in os.listdir(images_folder):\n",
    "    study_folder = os.path.join(images_folder, study_id)\n",
    "    clahe_study_folder = os.path.join(clahe_images_folder, study_id)\n",
    "    os.makedirs(clahe_study_folder, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(study_folder):\n",
    "        if file.endswith('.png'):\n",
    "            image_path = os.path.join(study_folder, file)\n",
    "            output_path = os.path.join(clahe_study_folder, file)\n",
    "\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Mammogram images are grayscale anyway\n",
    "            cv2.imwrite(output_path, clahe.apply(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2bae3a",
   "metadata": {},
   "source": [
    "### Splitting the Dataset (not required)\n",
    "\n",
    "In preparation for testing the CNN models against this dataset, the images should be split into those that will train the models and those that will test their performance. The VinDr-Mammo dataset has a pre-determined split indicated in the breast-level_annotations csv. The dataset has been split into 1,000 test exams and 4,000 training exams, with the frequencies of each BI-RADS category, density level, and abnormality category being preserved by applying an iterative stratification algorithm. This study will not attempt to improve on the stratification already achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Define and create folders\n",
    "clahe_folder = r'E:\\vindr-mammo-1.0.0\\clahe_images'\n",
    "data_folder = r\"E:\\vindr-mammo-1.0.0\"\n",
    "train_folder = os.path.join(data_folder, \"train_images\")\n",
    "test_folder = os.path.join(data_folder, \"test_images\")\n",
    "\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Load the pre-determined dataset split field\n",
    "annotations = pd.read_csv(f\"{data_folder}/breast-level_annotations.csv\")\n",
    "\n",
    "# Move images to their respective split folders\n",
    "for _, row in annotations.iterrows():\n",
    "    source_folder = os.path.join(clahe_folder, row['study_id'])\n",
    "    if not os.path.isdir(source_folder):\n",
    "        continue  \n",
    "\n",
    "    output_folder = train_folder if row['split'] == \"training\" else test_folder\n",
    "\n",
    "    for file in os.listdir(source_folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            shutil.move(os.path.join(source_folder, file), os.path.join(output_folder, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
